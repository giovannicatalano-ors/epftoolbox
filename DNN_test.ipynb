{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\CTLGNN00C\\AppData\\Local\\anaconda3\\envs\\epftoolbox\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from epftoolbox.models import hyperparameter_optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run C:\\Users\\CTLGNN00C\\Documents\\GitHub\\epftoolbox\\epftoolbox\\data\\_datasets.py\n",
    "%run C:\\Users\\CTLGNN00C\\Documents\\GitHub\\epftoolbox\\epftoolbox\\models\\_dnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/CTLGNN00C/Documents/ENERGY/Progetto MGP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = read_data(path, dataset = \"FR\") # Grouped dataframes (by date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters optimizer (don't run again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of layers in DNN\n",
    "nlayers = 2\n",
    "\n",
    "# Market under study. If it not one of the standard ones, the file name\n",
    "# has to be provided, where the file has to be a csv file\n",
    "dataset = 'FR'\n",
    "\n",
    "# Number of years (a year is 364 days) in the test dataset.\n",
    "years_test = 2\n",
    "\n",
    "# Optional parameters for selecting the test dataset, if either of them is not provided, \n",
    "# the test dataset is built using the years_test parameter. They should either be one of\n",
    "# the date formats existing in python or a string with the following format\n",
    "# \"%d/%m/%Y %H:%M\"\n",
    "begin_test_date = None\n",
    "end_test_date = None\n",
    "\n",
    "# Boolean that selects whether the validation and training datasets are shuffled\n",
    "shuffle_train = 1\n",
    "\n",
    "# Boolean that selects whether a data augmentation technique for DNNs is used\n",
    "data_augmentation = 0\n",
    "\n",
    "# Boolean that selects whether we start a new hyperparameter optimization or we restart an existing one\n",
    "new_hyperopt = 1\n",
    "\n",
    "# Number of years used in the training dataset for recalibration\n",
    "calibration_window = 4\n",
    "\n",
    "# Unique identifier to read the trials file of hyperparameter optimization\n",
    "experiment_id = 1\n",
    "\n",
    "# Number of iterations for hyperparameter optimization\n",
    "max_evals = 10\n",
    "\n",
    "path_datasets_folder = path\n",
    "path_hyperparameters_folder = path +  \"/experimental_files/\"\n",
    "\n",
    "# Check documentation of the hyperparameter_optimizer for each of the function parameters\n",
    "# In this example, we optimize a model for the PJM market.\n",
    "# We consider two directories, one for storing the datasets and the other one for the experimental files.\n",
    "# We start a hyperparameter optimization from scratch. We employ 1500 iterations in hyperopt,\n",
    "# 2 years of test data, a DNN with 2 hidden layers, a calibration window of 4 years,\n",
    "# we avoid data augmentation,  and we provide an experiment_id equal to 1\n",
    "hyperparameter_optimizer(path_datasets_folder=path_datasets_folder, \n",
    "                         path_hyperparameters_folder=path_hyperparameters_folder, \n",
    "                         new_hyperopt=new_hyperopt, max_evals=max_evals, nlayers=nlayers, dataset=dataset, \n",
    "                         years_test=years_test, calibration_window=calibration_window, \n",
    "                         shuffle_train=shuffle_train, data_augmentation=0, experiment_id=experiment_id,\n",
    "                         begin_test_date=begin_test_date, end_test_date=end_test_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pc\n",
    "\n",
    "# Percorso dove è stato salvato il file di ottimizzazione\n",
    "trials_file_path = os.path.join(path_hyperparameters_folder, 'DNN_hyperparameters_nl' + str(nlayers) +\n",
    "                                '_dat' + str(dataset) + '_YT' + str(years_test) + \n",
    "                                '_SF' * shuffle_train + '_DA' * data_augmentation + \n",
    "                                '_CW' + str(calibration_window) + '_' + str(experiment_id))\n",
    "\n",
    "# Caricare il file di trials salvato\n",
    "with open(trials_file_path, \"rb\") as f:\n",
    "    trials = pc.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 2,\n",
       " 'tid': 5,\n",
       " 'spec': None,\n",
       " 'result': {'loss': 6.541263089302935,\n",
       "  'MAE Val': 6.541263089302935,\n",
       "  'MAE Test': 7.3781093193566525,\n",
       "  'sMAPE Val': 14.114707598008739,\n",
       "  'sMAPE Test': 20.11082947304353,\n",
       "  'status': 'ok'},\n",
       " 'misc': {'tid': 5,\n",
       "  'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "  'workdir': None,\n",
       "  'idxs': {'In: Day': [5],\n",
       "   'In: Exog-1 D': [5],\n",
       "   'In: Exog-1 D-1': [5],\n",
       "   'In: Exog-1 D-7': [5],\n",
       "   'In: Exog-2 D': [5],\n",
       "   'In: Exog-2 D-1': [5],\n",
       "   'In: Exog-2 D-7': [5],\n",
       "   'In: Price D-1': [5],\n",
       "   'In: Price D-2': [5],\n",
       "   'In: Price D-3': [5],\n",
       "   'In: Price D-7': [5],\n",
       "   'activation': [5],\n",
       "   'batch_normalization': [5],\n",
       "   'dropout': [5],\n",
       "   'init': [5],\n",
       "   'lambdal1': [],\n",
       "   'lr': [5],\n",
       "   'neurons1': [5],\n",
       "   'neurons2': [5],\n",
       "   'reg': [5],\n",
       "   'scaleX': [5],\n",
       "   'scaleY': [5],\n",
       "   'seed': [5]},\n",
       "  'vals': {'In: Day': [1],\n",
       "   'In: Exog-1 D': [1],\n",
       "   'In: Exog-1 D-1': [1],\n",
       "   'In: Exog-1 D-7': [1],\n",
       "   'In: Exog-2 D': [1],\n",
       "   'In: Exog-2 D-1': [0],\n",
       "   'In: Exog-2 D-7': [0],\n",
       "   'In: Price D-1': [0],\n",
       "   'In: Price D-2': [0],\n",
       "   'In: Price D-3': [1],\n",
       "   'In: Price D-7': [0],\n",
       "   'activation': [5],\n",
       "   'batch_normalization': [1],\n",
       "   'dropout': [0.438890096383171],\n",
       "   'init': [1],\n",
       "   'lambdal1': [],\n",
       "   'lr': [0.003803651200105018],\n",
       "   'neurons1': [359.0],\n",
       "   'neurons2': [101.0],\n",
       "   'reg': [0],\n",
       "   'scaleX': [3],\n",
       "   'scaleY': [4],\n",
       "   'seed': [318.0]}},\n",
       " 'exp_key': None,\n",
       " 'owner': None,\n",
       " 'version': 0,\n",
       " 'book_time': datetime.datetime(2024, 9, 18, 15, 23, 47, 390000),\n",
       " 'refresh_time': datetime.datetime(2024, 9, 18, 15, 24, 19, 966000)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Miglior risultato dato dall'ottimizzatore\n",
    "trials.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'In: Day': [1],\n",
       " 'In: Exog-1 D': [1],\n",
       " 'In: Exog-1 D-1': [1],\n",
       " 'In: Exog-1 D-7': [1],\n",
       " 'In: Exog-2 D': [1],\n",
       " 'In: Exog-2 D-1': [0],\n",
       " 'In: Exog-2 D-7': [0],\n",
       " 'In: Price D-1': [0],\n",
       " 'In: Price D-2': [0],\n",
       " 'In: Price D-3': [1],\n",
       " 'In: Price D-7': [0],\n",
       " 'activation': [5],\n",
       " 'batch_normalization': [1],\n",
       " 'dropout': [0.438890096383171],\n",
       " 'init': [1],\n",
       " 'lambdal1': [],\n",
       " 'lr': [0.003803651200105018],\n",
       " 'neurons1': [359.0],\n",
       " 'neurons2': [101.0],\n",
       " 'reg': [0],\n",
       " 'scaleX': [3],\n",
       " 'scaleY': [4],\n",
       " 'seed': [318.0]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parametri migliori per la migliore configurazione\n",
    "best_trial = trials.best_trial\n",
    "best_hyperparams = best_trial['misc']['vals']\n",
    "best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione iperparametri\n",
    "activation = best_hyperparams['activation'][0]\n",
    "batch_normalization = best_hyperparams['batch_normalization'][0]\n",
    "dropout = best_hyperparams['dropout'][0]\n",
    "learning_rate = best_hyperparams['lr'][0]\n",
    "neurons1 = int(best_hyperparams['neurons1'][0])  # Converti in int per i neuroni\n",
    "neurons2 = int(best_hyperparams['neurons2'][0])\n",
    "scaleX = best_hyperparams['scaleX'][0]\n",
    "scaleY = best_hyperparams['scaleY'][0]\n",
    "seed = int(best_hyperparams['seed'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione features\n",
    "features = {}\n",
    "for feat in list(best_hyperparams.keys())[0:11]:\n",
    "    features[feat] = best_hyperparams[feat][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_hyperparams = format_best_trial(best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Exogenous 1</th>\n",
       "      <th>Exogenous 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-09 00:00:00</th>\n",
       "      <td>32.542</td>\n",
       "      <td>63065.0</td>\n",
       "      <td>63000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-09 01:00:00</th>\n",
       "      <td>21.549</td>\n",
       "      <td>62715.0</td>\n",
       "      <td>58800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-09 02:00:00</th>\n",
       "      <td>15.711</td>\n",
       "      <td>61952.0</td>\n",
       "      <td>58500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-09 03:00:00</th>\n",
       "      <td>10.583</td>\n",
       "      <td>59262.0</td>\n",
       "      <td>54300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-09 04:00:00</th>\n",
       "      <td>10.324</td>\n",
       "      <td>56883.0</td>\n",
       "      <td>51900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-03 19:00:00</th>\n",
       "      <td>47.620</td>\n",
       "      <td>77508.0</td>\n",
       "      <td>68739.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-03 20:00:00</th>\n",
       "      <td>43.790</td>\n",
       "      <td>75506.0</td>\n",
       "      <td>66734.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-03 21:00:00</th>\n",
       "      <td>42.440</td>\n",
       "      <td>72883.0</td>\n",
       "      <td>64515.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-03 22:00:00</th>\n",
       "      <td>42.030</td>\n",
       "      <td>72926.0</td>\n",
       "      <td>62554.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-03 23:00:00</th>\n",
       "      <td>40.910</td>\n",
       "      <td>73070.0</td>\n",
       "      <td>67342.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34944 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Price  Exogenous 1  Exogenous 2\n",
       "Date                                                 \n",
       "2011-01-09 00:00:00  32.542      63065.0      63000.0\n",
       "2011-01-09 01:00:00  21.549      62715.0      58800.0\n",
       "2011-01-09 02:00:00  15.711      61952.0      58500.0\n",
       "2011-01-09 03:00:00  10.583      59262.0      54300.0\n",
       "2011-01-09 04:00:00  10.324      56883.0      51900.0\n",
       "...                     ...          ...          ...\n",
       "2015-01-03 19:00:00  47.620      77508.0      68739.0\n",
       "2015-01-03 20:00:00  43.790      75506.0      66734.0\n",
       "2015-01-03 21:00:00  42.440      72883.0      64515.0\n",
       "2015-01-03 22:00:00  42.030      72926.0      62554.0\n",
       "2015-01-03 23:00:00  40.910      73070.0      67342.0\n",
       "\n",
       "[34944 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 97 is out of bounds for axis 1 with size 97",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43m_build_and_split_XYs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfTrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdfTest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_hyperparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_exogenous_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpercentage_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdate_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperoptimization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_augmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\epftoolbox\\epftoolbox\\models\\_dnn.py:944\u001b[0m, in \u001b[0;36m_build_and_split_XYs\u001b[1;34m(dfTrain, features, shuffle_train, n_exogenous_inputs, dfTest, percentage_val, date_test, hyperoptimization, data_augmentation)\u001b[0m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m exog \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_exogenous_inputs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    943\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn: Exog-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(exog) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m D-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(past_day)]:\n\u001b[1;32m--> 944\u001b[0m         \u001b[43mXtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexFeatures\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m dfTrain\u001b[38;5;241m.\u001b[39mloc[pastIndexTrain, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExogenous \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(exog)]                    \n\u001b[0;32m    945\u001b[0m         Xtest[:, indexFeatures] \u001b[38;5;241m=\u001b[39m dfTest\u001b[38;5;241m.\u001b[39mloc[pastIndexTest, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExogenous \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(exog)]\n\u001b[0;32m    946\u001b[0m         indexFeatures \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 97 is out of bounds for axis 1 with size 97"
     ]
    }
   ],
   "source": [
    "_build_and_split_XYs(dfTrain=train_df,dfTest=test_df,  features=opt_hyperparams, n_exogenous_inputs=2, shuffle_train=True, percentage_val=0.25,\n",
    "                        date_test=None, hyperoptimization=False, data_augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'In: Day': 1,\n",
       " 'In: Exog-1 D': 1,\n",
       " 'In: Exog-1 D-1': 1,\n",
       " 'In: Exog-1 D-7': 1,\n",
       " 'In: Exog-2 D': 1,\n",
       " 'In: Exog-2 D-1': 0,\n",
       " 'In: Exog-2 D-7': 0,\n",
       " 'In: Price D-1': 0,\n",
       " 'In: Price D-2': 0,\n",
       " 'In: Price D-3': 1,\n",
       " 'In: Price D-7': 0,\n",
       " 'activation': 'PReLU',\n",
       " 'batch_normalization': 1,\n",
       " 'dropout': 0.438890096383171,\n",
       " 'init': 'lecun_uniform',\n",
       " 'lambdal1': 0,\n",
       " 'lr': 0.003803651200105018,\n",
       " 'neurons1': 359.0,\n",
       " 'neurons2': 101.0,\n",
       " 'reg': None,\n",
       " 'scaleX': 'Std',\n",
       " 'scaleY': 'Median',\n",
       " 'seed': 318.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_hyperparams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epftoolbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
